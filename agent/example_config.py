"""
Agent ç¤ºä¾‹é…ç½®

æ¼”ç¤ºå¦‚ä½•é›†æˆå’Œä½¿ç”¨ Agent æ¨¡å—
"""

import asyncio
import os
from pathlib import Path

# ==================== LLM å®¢æˆ·ç«¯é…ç½® ====================

class MockLLMClient:
    """æ¨¡æ‹Ÿ LLM å®¢æˆ·ç«¯ï¼ˆå¼€å‘é˜¶æ®µï¼‰"""
    
    async def chat_completion(self, messages, **kwargs):
        """æ¨¡æ‹ŸèŠå¤©è¡¥å…¨"""
        import json
        
        # æ ¹æ®ç”¨æˆ·è¾“å…¥è¿”å›ç®€å•çš„æ¨¡æ‹Ÿå“åº”
        user_message = messages[-1]["content"]
        
        if "æœç´¢" in user_message or "TODO" in user_message:
            return type('Response', (), {
                'choices': [
                    type('Choice', (), {
                        'message': type('Message', (), {
                            'content': json.dumps({
                                "task_type": "code_search",
                                "steps": [
                                    {
                                        "step_id": "step_1",
                                        "tool_id": "code_search",
                                        "tool_name": "ä»£ç æœç´¢",
                                        "args": {"pattern": "TODO"},
                                        "reason": "æœç´¢ä»£ç ä¸­çš„ TODO æ³¨é‡Š",
                                        "depends_on": [],
                                        "retry_on_fail": False,
                                        "timeout_seconds": 30,
                                        "on_fail": "stop"
                                    }
                                ],
                                "estimated_duration": 30
                            }, ensure_ascii=False)
                        })()
                    })()
                ]
            })()
        
        # é»˜è®¤å“åº”
        return type('Response', (), {
            'choices': [
                type('Choice', (), {
                    'message': type('Message', (), {
                        'content': json.dumps({
                            "task_type": "custom",
                            "steps": [
                                {
                                    "step_id": "step_1",
                                    "tool_id": "example_tool",
                                    "tool_name": "ç¤ºä¾‹å·¥å…·",
                                    "args": {},
                                    "reason": "æ‰§è¡Œç”¨æˆ·è¯·æ±‚",
                                    "depends_on": [],
                                    "retry_on_fail": False,
                                    "timeout_seconds": 60,
                                    "on_fail": "stop"
                                }
                            ],
                            "estimated_duration": 60
                        }, ensure_ascii=False)
                    })()
                })()
            ]
        })()


# ä½¿ç”¨çœŸå® OpenAI å…¼å®¹å®¢æˆ·ç«¯ï¼ˆæ¨èï¼‰
# éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
#   OPENAI_API_KEY=your_key
#   OPENAI_BASE_URL=https://api.openai.com/v1  (å¯é€‰)
#   OPENAI_MODEL=gpt-4o-mini                   (å¯é€‰)
#
# from agent.llm_client import OpenAICompatibleClient
# llm_client = OpenAICompatibleClient()


# ==================== API å®¢æˆ·ç«¯é…ç½® ====================

class MockAPIClient:
    """æ¨¡æ‹Ÿ API å®¢æˆ·ç«¯ï¼ˆå¼€å‘é˜¶æ®µï¼‰"""
    
    async def create_run(self, tool_id, args, user_id):
        """åˆ›å»ºä»»åŠ¡"""
        import uuid
        return {
            "run_id": str(uuid.uuid4()),
            "status": "queued",
            "tool_id": tool_id
        }
    
    async def get_run_status(self, run_id):
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        return {
            "run_id": run_id,
            "status": "succeeded",
            "output": f"æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ: {run_id}"
        }


# ä½¿ç”¨çœŸå® API å®¢æˆ·ç«¯ï¼ˆå–æ¶ˆæ³¨é‡Šï¼‰
# import httpx
# 
# class APIClient:
#     def __init__(self, base_url: str, api_token: str):
#         self.base_url = base_url
#         self.headers = {"Authorization": f"Bearer {api_token}"}
#     
#     async def create_run(self, tool_id, args, user_id):
#         async with httpx.AsyncClient() as client:
#             response = await client.post(
#                 f"{self.base_url}/runs",
#                 json={"tool_id": tool_id, "args": args},
#                 headers=self.headers
#             )
#             return response.json()
#     
#     async def get_run_status(self, run_id):
#         async with httpx.AsyncClient() as client:
#             response = await client.get(
#                 f"{self.base_url}/runs/{run_id}",
#                 headers=self.headers
#             )
#             return response.json()


# ==================== å®¡æ‰¹å¤„ç†å™¨é…ç½® ====================

class MockApprovalHandler:
    """æ¨¡æ‹Ÿå®¡æ‰¹å¤„ç†å™¨"""
    
    async def wait_for_approval(self, approval_id, timeout=3600):
        """ç­‰å¾…å®¡æ‰¹"""
        # æ¨¡æ‹Ÿè‡ªåŠ¨æ‰¹å‡†
        await asyncio.sleep(0.1)
        return True


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

async def example_usage():
    """Agent ä½¿ç”¨ç¤ºä¾‹"""
    from automation_hub.agent import AgentPlanner, AgentExecutor, ConversationContext
    
    # é…ç½®
    db_path = "data/automation_hub.sqlite3"
    # llm_client = OpenAICompatibleClient()
    llm_client = MockLLMClient()
    api_client = MockAPIClient()
    approval_handler = MockApprovalHandler()
    
    # åˆå§‹åŒ–
    planner = AgentPlanner(llm_client, db_path)
    executor = AgentExecutor(api_client, approval_handler)
    
    # åˆ›å»ºå¯¹è¯ä¸Šä¸‹æ–‡
    context = ConversationContext(user_id="user123", session_id="session456")
    context.update_working_context(
        cwd="/home/user/project",
        project_type="python"
    )
    
    # ç”¨æˆ·æŸ¥è¯¢
    user_query = "æœç´¢æ‰€æœ‰ TODO æ³¨é‡Š"
    
    # ç”Ÿæˆè®¡åˆ’
    print("ğŸ¤– ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")
    plan = await planner.plan(user_query, context)
    
    print(f"ğŸ“‹ è®¡åˆ’ID: {plan.plan_id}")
    print(f"ğŸ“ ä»»åŠ¡ç±»å‹: {plan.task_type}")
    print(f"ğŸ”¢ æ­¥éª¤æ•°: {len(plan.steps)}")
    print(f"â±ï¸  é¢„è®¡æ—¶é•¿: {plan.estimated_duration}ç§’")
    
    for i, step in enumerate(plan.steps, 1):
        print(f"\næ­¥éª¤ {i}:")
        print(f"  å·¥å…·: {step.tool_name} ({step.tool_id})")
        print(f"  åŸå› : {step.reason}")
        print(f"  å‚æ•°: {step.args}")
    
    # æ‰§è¡Œè®¡åˆ’
    print("\n\nğŸš€ æ‰§è¡Œè®¡åˆ’...")
    result = await executor.execute_plan(plan, user_id="user123")
    
    print(f"\nâœ… æ‰§è¡ŒçŠ¶æ€: {result.status}")
    print(f"â±ï¸  æ€»è€—æ—¶: {result.total_duration:.2f}ç§’")
    print(f"\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
    print(result.summary)
    
    # æ·»åŠ åˆ°å¯¹è¯å†å²
    context.add_message("user", user_query)
    context.add_message("assistant", result.summary)


if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(example_usage())
